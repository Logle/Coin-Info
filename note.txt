Log: 12/16/2014

Bitcoin magazine is closed. Download all Bitcoin magazine content completed.

*************************************************************

Log: 12/15/2014

Refactor databases: idea: scraper for each site is a seperate library with similar code
style. Public API for each library. Now it is possible to run setInterval on each library if
the server is online 24/24

Next:
- check the codes and database once more
- download most recent data
- complete phase 1  Backend refactoring
- improve front-end

**************************************************************
Log: not sure the time
Objectives:

automate the backend content discovery proecess. Requirements:

- 1 bot for one website.
- initially the bot is started manually with the administator parameter. The bot then runs to collect relevant
articles following the said parameter.
- don't use external storage for header data.

current difficulties: working with async process of collecting header data and then use this header data
to go to individual page to collect the relevant information.

Solution: 1. use anyc library; 2. isolate ScaperBot as a complete module with an unique global namespace using self-invoked function pattern. 3. design ScraperBot API interface.

Next steps: re-write two files: ScraperAlpha to ScraperCoinTelegraph; ScraperBeta to ScraperCoinDesk; and ScraperBitcoinMagazine;